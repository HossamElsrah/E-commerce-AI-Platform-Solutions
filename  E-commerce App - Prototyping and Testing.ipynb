{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12762370,"sourceType":"datasetVersion","datasetId":8067870}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hossamelsrah/e-commerce-system-dev?scriptVersionId=256280605\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Project: E-commerce AI Assistan**t\n\nThis notebook is a development environment for building and testing the core AI functionalities of the E-commerce AI Assistant.\n\nKey Features:\n-   **Analytics Chatbot:** A powerful tool that allows users to upload a CSV file of their e-commerce data. Users can ask natural language questions about their sales, customer behavior, and product performance. The chatbot then provides data-driven insights and strategic recommendations.\n-   **RAG Assistant:** A dedicated knowledge base assistant. This application uses Retrieval-Augmented Generation (RAG) to search through internal documentation or product information and provide quick, contextual, and accurate answers to specific queries.\n\nThis is a working document for prototyping and model evaluation.\n","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:26:35.17137Z","iopub.execute_input":"2025-08-16T09:26:35.171681Z","iopub.status.idle":"2025-08-16T09:26:35.176093Z","shell.execute_reply.started":"2025-08-16T09:26:35.171651Z","shell.execute_reply":"2025-08-16T09:26:35.175509Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# *Ecommerce Analytics Chatbot*\nThis is our Main Featyre in The system\n## Environment Setup & Library Installation\nHere we'll prepare all the necessary tools and libraries to build our application.","metadata":{}},{"cell_type":"code","source":"# Install required libraries\n!pip install -q langchain accelerate chromadb faiss-cpu sentence-transformers transformers langchain-huggingface langchain_experimental\n!pip install opendatasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:26:42.186473Z","iopub.execute_input":"2025-08-16T09:26:42.18675Z","iopub.status.idle":"2025-08-16T09:26:49.430006Z","shell.execute_reply.started":"2025-08-16T09:26:42.186728Z","shell.execute_reply":"2025-08-16T09:26:49.429014Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\nRequirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.1)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.6.15)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.32.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.4)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\nRequirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\nRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.5.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Data Loading & Preprocessing\n* To test our model on critical e-commerce challenges, such as customer churn, demand forecasting, and cross-selling, we need to load and prepare a clean dataset.\n* This step ensures the data is ready for analysis and model training.","metadata":{}},{"cell_type":"code","source":"import opendatasets as od\nod.download('https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:27:06.15983Z","iopub.execute_input":"2025-08-16T09:27:06.160611Z","iopub.status.idle":"2025-08-16T09:28:44.394294Z","shell.execute_reply.started":"2025-08-16T09:27:06.160578Z","shell.execute_reply":"2025-08-16T09:28:44.393695Z"}},"outputs":[{"name":"stdout","text":"Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\nYour Kaggle username:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  hossamelsrah\n"},{"name":"stdout","text":"Your Kaggle Key:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\nDownloading brazilian-ecommerce.zip to ./brazilian-ecommerce\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 42.6M/42.6M [00:00<00:00, 1.09GB/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\norders = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_orders_dataset.csv')\norder_items = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_products_dataset.csv')\nproducts = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_order_items_dataset.csv')\norder_payments = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_order_payments_dataset.csv')\nreviews = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_order_reviews_dataset.csv')\nsellers = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_sellers_dataset.csv')\ngeolocation = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_geolocation_dataset.csv')\ncustomers = pd.read_csv('/kaggle/working/brazilian-ecommerce/olist_customers_dataset.csv')\nproduct_category = pd.read_csv('/kaggle/working/brazilian-ecommerce/product_category_name_translation.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:28:48.406691Z","iopub.execute_input":"2025-08-16T09:28:48.407586Z","iopub.status.idle":"2025-08-16T09:28:50.835083Z","shell.execute_reply.started":"2025-08-16T09:28:48.40756Z","shell.execute_reply":"2025-08-16T09:28:50.834528Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Some Explorition & Preprocessing","metadata":{}},{"cell_type":"code","source":"merged_data = orders.merge(products, on='order_id', how='left')\nmerged_data = merged_data.merge(order_items[['product_id', 'product_category_name']], on='product_id', how='left')\nmerged_data = merged_data.merge(order_payments, on='order_id', how='left')\nmerged_data = merged_data.merge(reviews, on='order_id', how='left')\nmerged_data = merged_data.merge(sellers, on='seller_id', how='left')\nmerged_data = merged_data.merge(customers, on='customer_id', how='left')\nmerged_data = merged_data.merge(product_category, on='product_category_name', how='left')\ndisplay(merged_data.head().T)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:28:53.429372Z","iopub.execute_input":"2025-08-16T09:28:53.429658Z","iopub.status.idle":"2025-08-16T09:28:54.567386Z","shell.execute_reply.started":"2025-08-16T09:28:53.429637Z","shell.execute_reply":"2025-08-16T09:28:54.566689Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                                               0  \\\norder_id                                        e481f51cbdc54678b7cc49136f2d6af7   \ncustomer_id                                     9ef432eb6251297304e76186b10a928d   \norder_status                                                           delivered   \norder_purchase_timestamp                                     2017-10-02 10:56:33   \norder_approved_at                                            2017-10-02 11:07:15   \norder_delivered_carrier_date                                 2017-10-04 19:55:00   \norder_delivered_customer_date                                2017-10-10 21:25:13   \norder_estimated_delivery_date                                2017-10-18 00:00:00   \norder_item_id                                                                1.0   \nproduct_id                                      87285b34884572647811a353c7ac498a   \nseller_id                                       3504c0cb71d7fa48d967e0e4c94d59d9   \nshipping_limit_date                                          2017-10-06 11:07:15   \nprice                                                                      29.99   \nfreight_value                                                               8.72   \nproduct_category_name                                      utilidades_domesticas   \npayment_sequential                                                           1.0   \npayment_type                                                         credit_card   \npayment_installments                                                         1.0   \npayment_value                                                              18.12   \nreview_id                                       a54f0611adc9ed256b57ede6b6eb5114   \nreview_score                                                                 4.0   \nreview_comment_title                                                         NaN   \nreview_comment_message         Não testei o produto ainda, mas ele veio corre...   \nreview_creation_date                                         2017-10-11 00:00:00   \nreview_answer_timestamp                                      2017-10-12 03:43:48   \nseller_zip_code_prefix                                                    9350.0   \nseller_city                                                                 maua   \nseller_state                                                                  SP   \ncustomer_unique_id                              7c396fd4830fd04220f754e42b4e5bff   \ncustomer_zip_code_prefix                                                    3149   \ncustomer_city                                                          sao paulo   \ncustomer_state                                                                SP   \nproduct_category_name_english                                         housewares   \n\n                                                                               1  \\\norder_id                                        e481f51cbdc54678b7cc49136f2d6af7   \ncustomer_id                                     9ef432eb6251297304e76186b10a928d   \norder_status                                                           delivered   \norder_purchase_timestamp                                     2017-10-02 10:56:33   \norder_approved_at                                            2017-10-02 11:07:15   \norder_delivered_carrier_date                                 2017-10-04 19:55:00   \norder_delivered_customer_date                                2017-10-10 21:25:13   \norder_estimated_delivery_date                                2017-10-18 00:00:00   \norder_item_id                                                                1.0   \nproduct_id                                      87285b34884572647811a353c7ac498a   \nseller_id                                       3504c0cb71d7fa48d967e0e4c94d59d9   \nshipping_limit_date                                          2017-10-06 11:07:15   \nprice                                                                      29.99   \nfreight_value                                                               8.72   \nproduct_category_name                                      utilidades_domesticas   \npayment_sequential                                                           3.0   \npayment_type                                                             voucher   \npayment_installments                                                         1.0   \npayment_value                                                                2.0   \nreview_id                                       a54f0611adc9ed256b57ede6b6eb5114   \nreview_score                                                                 4.0   \nreview_comment_title                                                         NaN   \nreview_comment_message         Não testei o produto ainda, mas ele veio corre...   \nreview_creation_date                                         2017-10-11 00:00:00   \nreview_answer_timestamp                                      2017-10-12 03:43:48   \nseller_zip_code_prefix                                                    9350.0   \nseller_city                                                                 maua   \nseller_state                                                                  SP   \ncustomer_unique_id                              7c396fd4830fd04220f754e42b4e5bff   \ncustomer_zip_code_prefix                                                    3149   \ncustomer_city                                                          sao paulo   \ncustomer_state                                                                SP   \nproduct_category_name_english                                         housewares   \n\n                                                                               2  \\\norder_id                                        e481f51cbdc54678b7cc49136f2d6af7   \ncustomer_id                                     9ef432eb6251297304e76186b10a928d   \norder_status                                                           delivered   \norder_purchase_timestamp                                     2017-10-02 10:56:33   \norder_approved_at                                            2017-10-02 11:07:15   \norder_delivered_carrier_date                                 2017-10-04 19:55:00   \norder_delivered_customer_date                                2017-10-10 21:25:13   \norder_estimated_delivery_date                                2017-10-18 00:00:00   \norder_item_id                                                                1.0   \nproduct_id                                      87285b34884572647811a353c7ac498a   \nseller_id                                       3504c0cb71d7fa48d967e0e4c94d59d9   \nshipping_limit_date                                          2017-10-06 11:07:15   \nprice                                                                      29.99   \nfreight_value                                                               8.72   \nproduct_category_name                                      utilidades_domesticas   \npayment_sequential                                                           2.0   \npayment_type                                                             voucher   \npayment_installments                                                         1.0   \npayment_value                                                              18.59   \nreview_id                                       a54f0611adc9ed256b57ede6b6eb5114   \nreview_score                                                                 4.0   \nreview_comment_title                                                         NaN   \nreview_comment_message         Não testei o produto ainda, mas ele veio corre...   \nreview_creation_date                                         2017-10-11 00:00:00   \nreview_answer_timestamp                                      2017-10-12 03:43:48   \nseller_zip_code_prefix                                                    9350.0   \nseller_city                                                                 maua   \nseller_state                                                                  SP   \ncustomer_unique_id                              7c396fd4830fd04220f754e42b4e5bff   \ncustomer_zip_code_prefix                                                    3149   \ncustomer_city                                                          sao paulo   \ncustomer_state                                                                SP   \nproduct_category_name_english                                         housewares   \n\n                                                              3  \\\norder_id                       53cdb2fc8bc7dce0b6741e2150273451   \ncustomer_id                    b0830fb4747a6c6d20dea0b8c802d7ef   \norder_status                                          delivered   \norder_purchase_timestamp                    2018-07-24 20:41:37   \norder_approved_at                           2018-07-26 03:24:27   \norder_delivered_carrier_date                2018-07-26 14:31:00   \norder_delivered_customer_date               2018-08-07 15:27:45   \norder_estimated_delivery_date               2018-08-13 00:00:00   \norder_item_id                                               1.0   \nproduct_id                     595fac2a385ac33a80bd5114aec74eb8   \nseller_id                      289cdb325fb7e7f891c38608bf9e0962   \nshipping_limit_date                         2018-07-30 03:24:27   \nprice                                                     118.7   \nfreight_value                                             22.76   \nproduct_category_name                                perfumaria   \npayment_sequential                                          1.0   \npayment_type                                             boleto   \npayment_installments                                        1.0   \npayment_value                                            141.46   \nreview_id                      8d5266042046a06655c8db133d120ba5   \nreview_score                                                4.0   \nreview_comment_title                           Muito boa a loja   \nreview_comment_message                     Muito bom o produto.   \nreview_creation_date                        2018-08-08 00:00:00   \nreview_answer_timestamp                     2018-08-08 18:37:50   \nseller_zip_code_prefix                                  31570.0   \nseller_city                                      belo horizonte   \nseller_state                                                 SP   \ncustomer_unique_id             af07308b275d755c9edb36a90c618231   \ncustomer_zip_code_prefix                                  47813   \ncustomer_city                                         barreiras   \ncustomer_state                                               BA   \nproduct_category_name_english                         perfumery   \n\n                                                              4  \norder_id                       47770eb9100c2d0c44946d9cf07ec65d  \ncustomer_id                    41ce2a54c0b03bf3443c3d931a367089  \norder_status                                          delivered  \norder_purchase_timestamp                    2018-08-08 08:38:49  \norder_approved_at                           2018-08-08 08:55:23  \norder_delivered_carrier_date                2018-08-08 13:50:00  \norder_delivered_customer_date               2018-08-17 18:06:29  \norder_estimated_delivery_date               2018-09-04 00:00:00  \norder_item_id                                               1.0  \nproduct_id                     aa4383b373c6aca5d8797843e5594415  \nseller_id                      4869f7a5dfa277a7dca6462dcf3b52b2  \nshipping_limit_date                         2018-08-13 08:55:23  \nprice                                                     159.9  \nfreight_value                                             19.22  \nproduct_category_name                                automotivo  \npayment_sequential                                          1.0  \npayment_type                                        credit_card  \npayment_installments                                        3.0  \npayment_value                                            179.12  \nreview_id                      e73b67b67587f7644d5bd1a52deb1b01  \nreview_score                                                5.0  \nreview_comment_title                                        NaN  \nreview_comment_message                                      NaN  \nreview_creation_date                        2018-08-18 00:00:00  \nreview_answer_timestamp                     2018-08-22 19:07:58  \nseller_zip_code_prefix                                  14840.0  \nseller_city                                             guariba  \nseller_state                                                 SP  \ncustomer_unique_id             3a653a41f6f9fc3d2a113cf8398680e8  \ncustomer_zip_code_prefix                                  75265  \ncustomer_city                                        vianopolis  \ncustomer_state                                               GO  \nproduct_category_name_english                              auto  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>order_id</th>\n      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n    </tr>\n    <tr>\n      <th>customer_id</th>\n      <td>9ef432eb6251297304e76186b10a928d</td>\n      <td>9ef432eb6251297304e76186b10a928d</td>\n      <td>9ef432eb6251297304e76186b10a928d</td>\n      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n    </tr>\n    <tr>\n      <th>order_status</th>\n      <td>delivered</td>\n      <td>delivered</td>\n      <td>delivered</td>\n      <td>delivered</td>\n      <td>delivered</td>\n    </tr>\n    <tr>\n      <th>order_purchase_timestamp</th>\n      <td>2017-10-02 10:56:33</td>\n      <td>2017-10-02 10:56:33</td>\n      <td>2017-10-02 10:56:33</td>\n      <td>2018-07-24 20:41:37</td>\n      <td>2018-08-08 08:38:49</td>\n    </tr>\n    <tr>\n      <th>order_approved_at</th>\n      <td>2017-10-02 11:07:15</td>\n      <td>2017-10-02 11:07:15</td>\n      <td>2017-10-02 11:07:15</td>\n      <td>2018-07-26 03:24:27</td>\n      <td>2018-08-08 08:55:23</td>\n    </tr>\n    <tr>\n      <th>order_delivered_carrier_date</th>\n      <td>2017-10-04 19:55:00</td>\n      <td>2017-10-04 19:55:00</td>\n      <td>2017-10-04 19:55:00</td>\n      <td>2018-07-26 14:31:00</td>\n      <td>2018-08-08 13:50:00</td>\n    </tr>\n    <tr>\n      <th>order_delivered_customer_date</th>\n      <td>2017-10-10 21:25:13</td>\n      <td>2017-10-10 21:25:13</td>\n      <td>2017-10-10 21:25:13</td>\n      <td>2018-08-07 15:27:45</td>\n      <td>2018-08-17 18:06:29</td>\n    </tr>\n    <tr>\n      <th>order_estimated_delivery_date</th>\n      <td>2017-10-18 00:00:00</td>\n      <td>2017-10-18 00:00:00</td>\n      <td>2017-10-18 00:00:00</td>\n      <td>2018-08-13 00:00:00</td>\n      <td>2018-09-04 00:00:00</td>\n    </tr>\n    <tr>\n      <th>order_item_id</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>product_id</th>\n      <td>87285b34884572647811a353c7ac498a</td>\n      <td>87285b34884572647811a353c7ac498a</td>\n      <td>87285b34884572647811a353c7ac498a</td>\n      <td>595fac2a385ac33a80bd5114aec74eb8</td>\n      <td>aa4383b373c6aca5d8797843e5594415</td>\n    </tr>\n    <tr>\n      <th>seller_id</th>\n      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n    </tr>\n    <tr>\n      <th>shipping_limit_date</th>\n      <td>2017-10-06 11:07:15</td>\n      <td>2017-10-06 11:07:15</td>\n      <td>2017-10-06 11:07:15</td>\n      <td>2018-07-30 03:24:27</td>\n      <td>2018-08-13 08:55:23</td>\n    </tr>\n    <tr>\n      <th>price</th>\n      <td>29.99</td>\n      <td>29.99</td>\n      <td>29.99</td>\n      <td>118.7</td>\n      <td>159.9</td>\n    </tr>\n    <tr>\n      <th>freight_value</th>\n      <td>8.72</td>\n      <td>8.72</td>\n      <td>8.72</td>\n      <td>22.76</td>\n      <td>19.22</td>\n    </tr>\n    <tr>\n      <th>product_category_name</th>\n      <td>utilidades_domesticas</td>\n      <td>utilidades_domesticas</td>\n      <td>utilidades_domesticas</td>\n      <td>perfumaria</td>\n      <td>automotivo</td>\n    </tr>\n    <tr>\n      <th>payment_sequential</th>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>payment_type</th>\n      <td>credit_card</td>\n      <td>voucher</td>\n      <td>voucher</td>\n      <td>boleto</td>\n      <td>credit_card</td>\n    </tr>\n    <tr>\n      <th>payment_installments</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>payment_value</th>\n      <td>18.12</td>\n      <td>2.0</td>\n      <td>18.59</td>\n      <td>141.46</td>\n      <td>179.12</td>\n    </tr>\n    <tr>\n      <th>review_id</th>\n      <td>a54f0611adc9ed256b57ede6b6eb5114</td>\n      <td>a54f0611adc9ed256b57ede6b6eb5114</td>\n      <td>a54f0611adc9ed256b57ede6b6eb5114</td>\n      <td>8d5266042046a06655c8db133d120ba5</td>\n      <td>e73b67b67587f7644d5bd1a52deb1b01</td>\n    </tr>\n    <tr>\n      <th>review_score</th>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>review_comment_title</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Muito boa a loja</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>review_comment_message</th>\n      <td>Não testei o produto ainda, mas ele veio corre...</td>\n      <td>Não testei o produto ainda, mas ele veio corre...</td>\n      <td>Não testei o produto ainda, mas ele veio corre...</td>\n      <td>Muito bom o produto.</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>review_creation_date</th>\n      <td>2017-10-11 00:00:00</td>\n      <td>2017-10-11 00:00:00</td>\n      <td>2017-10-11 00:00:00</td>\n      <td>2018-08-08 00:00:00</td>\n      <td>2018-08-18 00:00:00</td>\n    </tr>\n    <tr>\n      <th>review_answer_timestamp</th>\n      <td>2017-10-12 03:43:48</td>\n      <td>2017-10-12 03:43:48</td>\n      <td>2017-10-12 03:43:48</td>\n      <td>2018-08-08 18:37:50</td>\n      <td>2018-08-22 19:07:58</td>\n    </tr>\n    <tr>\n      <th>seller_zip_code_prefix</th>\n      <td>9350.0</td>\n      <td>9350.0</td>\n      <td>9350.0</td>\n      <td>31570.0</td>\n      <td>14840.0</td>\n    </tr>\n    <tr>\n      <th>seller_city</th>\n      <td>maua</td>\n      <td>maua</td>\n      <td>maua</td>\n      <td>belo horizonte</td>\n      <td>guariba</td>\n    </tr>\n    <tr>\n      <th>seller_state</th>\n      <td>SP</td>\n      <td>SP</td>\n      <td>SP</td>\n      <td>SP</td>\n      <td>SP</td>\n    </tr>\n    <tr>\n      <th>customer_unique_id</th>\n      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n      <td>af07308b275d755c9edb36a90c618231</td>\n      <td>3a653a41f6f9fc3d2a113cf8398680e8</td>\n    </tr>\n    <tr>\n      <th>customer_zip_code_prefix</th>\n      <td>3149</td>\n      <td>3149</td>\n      <td>3149</td>\n      <td>47813</td>\n      <td>75265</td>\n    </tr>\n    <tr>\n      <th>customer_city</th>\n      <td>sao paulo</td>\n      <td>sao paulo</td>\n      <td>sao paulo</td>\n      <td>barreiras</td>\n      <td>vianopolis</td>\n    </tr>\n    <tr>\n      <th>customer_state</th>\n      <td>SP</td>\n      <td>SP</td>\n      <td>SP</td>\n      <td>BA</td>\n      <td>GO</td>\n    </tr>\n    <tr>\n      <th>product_category_name_english</th>\n      <td>housewares</td>\n      <td>housewares</td>\n      <td>housewares</td>\n      <td>perfumery</td>\n      <td>auto</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"merged_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:28:54.568408Z","iopub.execute_input":"2025-08-16T09:28:54.568685Z","iopub.status.idle":"2025-08-16T09:28:54.766469Z","shell.execute_reply.started":"2025-08-16T09:28:54.568663Z","shell.execute_reply":"2025-08-16T09:28:54.765657Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 119143 entries, 0 to 119142\nData columns (total 33 columns):\n #   Column                         Non-Null Count   Dtype  \n---  ------                         --------------   -----  \n 0   order_id                       119143 non-null  object \n 1   customer_id                    119143 non-null  object \n 2   order_status                   119143 non-null  object \n 3   order_purchase_timestamp       119143 non-null  object \n 4   order_approved_at              118966 non-null  object \n 5   order_delivered_carrier_date   117057 non-null  object \n 6   order_delivered_customer_date  115722 non-null  object \n 7   order_estimated_delivery_date  119143 non-null  object \n 8   order_item_id                  118310 non-null  float64\n 9   product_id                     118310 non-null  object \n 10  seller_id                      118310 non-null  object \n 11  shipping_limit_date            118310 non-null  object \n 12  price                          118310 non-null  float64\n 13  freight_value                  118310 non-null  float64\n 14  product_category_name          116601 non-null  object \n 15  payment_sequential             119140 non-null  float64\n 16  payment_type                   119140 non-null  object \n 17  payment_installments           119140 non-null  float64\n 18  payment_value                  119140 non-null  float64\n 19  review_id                      118146 non-null  object \n 20  review_score                   118146 non-null  float64\n 21  review_comment_title           13989 non-null   object \n 22  review_comment_message         50245 non-null   object \n 23  review_creation_date           118146 non-null  object \n 24  review_answer_timestamp        118146 non-null  object \n 25  seller_zip_code_prefix         118310 non-null  float64\n 26  seller_city                    118310 non-null  object \n 27  seller_state                   118310 non-null  object \n 28  customer_unique_id             119143 non-null  object \n 29  customer_zip_code_prefix       119143 non-null  int64  \n 30  customer_city                  119143 non-null  object \n 31  customer_state                 119143 non-null  object \n 32  product_category_name_english  116576 non-null  object \ndtypes: float64(8), int64(1), object(24)\nmemory usage: 30.0+ MB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"merged_data=merged_data.drop(columns=[\"order_id\",\"customer_id\",\"order_approved_at\",\"order_delivered_carrier_date\",\"order_item_id\"\n,\"product_id\",\"seller_id\",\"shipping_limit_date\",\"payment_sequential\"\n,\"payment_installments\",\"review_id\",\"review_creation_date\",\"review_answer_timestamp\"\n,\"seller_zip_code_prefix\",\"seller_state\",\"seller_city\"\n,\"customer_unique_id\",\"customer_zip_code_prefix\",\"review_comment_title\",\"review_comment_message\",\"order_purchase_timestamp\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:28:58.566474Z","iopub.execute_input":"2025-08-16T09:28:58.567271Z","iopub.status.idle":"2025-08-16T09:28:58.601476Z","shell.execute_reply.started":"2025-08-16T09:28:58.567227Z","shell.execute_reply":"2025-08-16T09:28:58.600941Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"merged_data.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:28:59.271606Z","iopub.execute_input":"2025-08-16T09:28:59.272141Z","iopub.status.idle":"2025-08-16T09:28:59.322189Z","shell.execute_reply.started":"2025-08-16T09:28:59.272121Z","shell.execute_reply":"2025-08-16T09:28:59.321489Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"order_status                        0\norder_delivered_customer_date    3421\norder_estimated_delivery_date       0\nprice                             833\nfreight_value                     833\nproduct_category_name            2542\npayment_type                        3\npayment_value                       3\nreview_score                      997\ncustomer_city                       0\ncustomer_state                      0\nproduct_category_name_english    2567\ndtype: int64"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"merged_data[\"product_category_name_english\"] = merged_data[\"product_category_name_english\"].fillna(merged_data[\"product_category_name_english\"].mode()[0])\nmerged_data['payment_type'] = merged_data['payment_type'].fillna(merged_data['payment_type'].mode()[0])\n\n# For numerical columns, fill with mean\nfor col in ['review_score', 'payment_value', 'freight_value', 'price','delivery_time_difference']:\n     if col in merged_data.columns:\n        merged_data[col] = merged_data[col].fillna(merged_data[col].mean())\n\nmerged_data.drop(columns=[\"order_estimated_delivery_date\",\"order_delivered_customer_date\",\"product_category_name\"],inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:01.175259Z","iopub.execute_input":"2025-08-16T09:29:01.175492Z","iopub.status.idle":"2025-08-16T09:29:01.222876Z","shell.execute_reply.started":"2025-08-16T09:29:01.175476Z","shell.execute_reply":"2025-08-16T09:29:01.222333Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"merged_data.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:03.25807Z","iopub.execute_input":"2025-08-16T09:29:03.258736Z","iopub.status.idle":"2025-08-16T09:29:03.311161Z","shell.execute_reply.started":"2025-08-16T09:29:03.258712Z","shell.execute_reply":"2025-08-16T09:29:03.31058Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"15850"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"merged_data.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:04.610783Z","iopub.execute_input":"2025-08-16T09:29:04.61101Z","iopub.status.idle":"2025-08-16T09:29:04.667197Z","shell.execute_reply.started":"2025-08-16T09:29:04.610993Z","shell.execute_reply":"2025-08-16T09:29:04.666643Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"merged_data.sample()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:06.017934Z","iopub.execute_input":"2025-08-16T09:29:06.018205Z","iopub.status.idle":"2025-08-16T09:29:06.032199Z","shell.execute_reply.started":"2025-08-16T09:29:06.018151Z","shell.execute_reply":"2025-08-16T09:29:06.031538Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"      order_status  price  freight_value payment_type  payment_value  \\\n94699    delivered  82.99          15.46  credit_card          98.45   \n\n       review_score   customer_city customer_state  \\\n94699           5.0  rio de janeiro             RJ   \n\n      product_category_name_english  \n94699                sports_leisure  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_status</th>\n      <th>price</th>\n      <th>freight_value</th>\n      <th>payment_type</th>\n      <th>payment_value</th>\n      <th>review_score</th>\n      <th>customer_city</th>\n      <th>customer_state</th>\n      <th>product_category_name_english</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>94699</th>\n      <td>delivered</td>\n      <td>82.99</td>\n      <td>15.46</td>\n      <td>credit_card</td>\n      <td>98.45</td>\n      <td>5.0</td>\n      <td>rio de janeiro</td>\n      <td>RJ</td>\n      <td>sports_leisure</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"merged_data = merged_data.rename(columns={\n    'product_category_name_english': 'category',\n    'review_score': 'review',\n    'freight_value': 'freight',\n    'payment_type': 'payment_method'\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:07.708962Z","iopub.execute_input":"2025-08-16T09:29:07.709256Z","iopub.status.idle":"2025-08-16T09:29:07.722956Z","shell.execute_reply.started":"2025-08-16T09:29:07.709215Z","shell.execute_reply":"2025-08-16T09:29:07.722314Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"data = merged_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:09.30183Z","iopub.execute_input":"2025-08-16T09:29:09.302082Z","iopub.status.idle":"2025-08-16T09:29:09.305609Z","shell.execute_reply.started":"2025-08-16T09:29:09.302063Z","shell.execute_reply":"2025-08-16T09:29:09.304929Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"data.sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:09.933455Z","iopub.execute_input":"2025-08-16T09:29:09.934184Z","iopub.status.idle":"2025-08-16T09:29:09.9483Z","shell.execute_reply.started":"2025-08-16T09:29:09.93414Z","shell.execute_reply":"2025-08-16T09:29:09.947692Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"       order_status   price  freight payment_method  payment_value  review  \\\n32692     delivered  129.90    27.46    credit_card         157.36     1.0   \n111497    delivered   44.79    15.11        voucher          59.90     4.0   \n27239     delivered   22.50    33.43    credit_card          55.93     2.0   \n55460     delivered   29.00    15.79    credit_card          44.79     1.0   \n16203     delivered  239.70    19.45    credit_card         259.15     5.0   \n\n         customer_city customer_state           category  \n32692        fortaleza             CE     sports_leisure  \n111497  belo horizonte             MG               baby  \n27239        sao paulo             SP     sports_leisure  \n55460         salvador             BA      watches_gifts  \n16203        sao paulo             SP  home_construction  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_status</th>\n      <th>price</th>\n      <th>freight</th>\n      <th>payment_method</th>\n      <th>payment_value</th>\n      <th>review</th>\n      <th>customer_city</th>\n      <th>customer_state</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32692</th>\n      <td>delivered</td>\n      <td>129.90</td>\n      <td>27.46</td>\n      <td>credit_card</td>\n      <td>157.36</td>\n      <td>1.0</td>\n      <td>fortaleza</td>\n      <td>CE</td>\n      <td>sports_leisure</td>\n    </tr>\n    <tr>\n      <th>111497</th>\n      <td>delivered</td>\n      <td>44.79</td>\n      <td>15.11</td>\n      <td>voucher</td>\n      <td>59.90</td>\n      <td>4.0</td>\n      <td>belo horizonte</td>\n      <td>MG</td>\n      <td>baby</td>\n    </tr>\n    <tr>\n      <th>27239</th>\n      <td>delivered</td>\n      <td>22.50</td>\n      <td>33.43</td>\n      <td>credit_card</td>\n      <td>55.93</td>\n      <td>2.0</td>\n      <td>sao paulo</td>\n      <td>SP</td>\n      <td>sports_leisure</td>\n    </tr>\n    <tr>\n      <th>55460</th>\n      <td>delivered</td>\n      <td>29.00</td>\n      <td>15.79</td>\n      <td>credit_card</td>\n      <td>44.79</td>\n      <td>1.0</td>\n      <td>salvador</td>\n      <td>BA</td>\n      <td>watches_gifts</td>\n    </tr>\n    <tr>\n      <th>16203</th>\n      <td>delivered</td>\n      <td>239.70</td>\n      <td>19.45</td>\n      <td>credit_card</td>\n      <td>259.15</td>\n      <td>5.0</td>\n      <td>sao paulo</td>\n      <td>SP</td>\n      <td>home_construction</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## Building the Language Model (LLM)\n- We will use the **google/flan-t5-xl** model as the core of our application. \n- Since we'll be working with CSV data, we will specifically employ a structured retrieval RAG approach to optimize its performance.","metadata":{}},{"cell_type":"markdown","source":"### LLM For Analyze The Data","metadata":{}},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain_huggingface import HuggingFacePipeline\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\nfrom langchain.chains import RetrievalQA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:31:42.433658Z","iopub.execute_input":"2025-08-16T09:31:42.433891Z","iopub.status.idle":"2025-08-16T09:31:42.438156Z","shell.execute_reply.started":"2025-08-16T09:31:42.433872Z","shell.execute_reply":"2025-08-16T09:31:42.437445Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Language Model Setup\n# This cell sets up the Large Language Model (LLM) and its pipeline.\n# Load the tokenizer and model for the T5 family.\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-xl\")\n\n# Create a text-generation pipeline using the model and tokenizer.\npipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=1024, device=0)\n\n# Wrap the pipeline in a LangChain HuggingFacePipeline for easy integration.\nllm = HuggingFacePipeline(pipeline=pipe)\n\nprint(\"HuggingFace pipeline and LLM initialized successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:29:47.469856Z","iopub.execute_input":"2025-08-16T09:29:47.470422Z","iopub.status.idle":"2025-08-16T09:31:42.432122Z","shell.execute_reply.started":"2025-08-16T09:29:47.470402Z","shell.execute_reply":"2025-08-16T09:31:42.431235Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11fefda63a9f45bb8832989d39f7465f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60c47b2afd7a48adafdd71974fa5bcb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab87d53a0d544288a591869ae0c24034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc5c3efe516d44df8df274a4d9256090"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8bfa7c1600149ccade16fe9371b47da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86eb7267eb474721a21464a58b943f04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30d1c450a35b4824a857d98ef0f6a4fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805e1b9af17541abafacee107765f650"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e888b6b6af2046218e49b187f4baa053"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"598dbff85085489ca8cd877b1b06a938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d47701fc1a49dda9927979ee546fb2"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"HuggingFace pipeline and LLM initialized successfully.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# A dictionary mapping a keyword to the corresponding pandas expression.\nPANDAS_EXPRESSIONS = {\n    # General order information\n    \"total_orders\": \"len(data)\",\n    \"order_statuses_count\": \"data['order_status'].value_counts()\",\n    \"unique_product_categories_count\": \"data['category'].nunique()\",\n    \n    # Financial insights\n    \"total_sales_value\": \"data['price'].sum()\",\n    \"total_freight_value\": \"data['freight'].sum()\",\n    \"total_payment_value\": \"data['payment_value'].sum()\",\n    \"avg_payment_value\": \"data['payment_value'].mean()\",\n    \"avg_freight_value\": \"data['freight'].mean()\",\n    \"avg_price_per_product\": \"data['price'].mean()\",\n    \"most_expensive_product_price\": \"data['price'].max()\",\n    \"least_expensive_product_price\": \"data['price'].min()\",\n    \"median_price\": \"data['price'].median()\", # New: Median price\n    \"std_dev_price\": \"data['price'].std()\", # New: Standard deviation of prices\n    \n    # Product and category insights\n    \"count_orders_per_category\": \"data.groupby('category')['order_status'].count()\",\n    \"avg_price_per_category\": \"data.groupby('category')['price'].mean()\",\n    \"top_3_categories_by_sales\": \"data.groupby('category')['price'].sum().nlargest(3)\",\n    \"top_5_categories_by_sales\": \"data.groupby('category')['price'].sum().nlargest(5)\",\n    \"bottom_5_categories_by_sales\": \"data.groupby('category')['price'].sum().nsmallest(5)\",\n    \"most_popular_category\": \"data['category'].mode()[0]\", # New: Most popular category\n    \n    # Payment and review analysis\n    \"reviews_per_category\": \"data.groupby('category')['review'].count()\",\n    \"most_common_payment_type\": \"data['payment_method'].mode()[0]\",\n    \"avg_review_score\": \"data['review'].mean()\",\n    \"reviews_by_score\": \"data['review'].value_counts().sort_index()\",\n    \"reviews_per_state\": \"data.groupby('customer_state')['review'].mean()\", # New: Average review score per state\n    \n    # Geographic data\n    \"city_with_most_orders\": \"data['customer_city'].mode()[0]\",\n    \"state_with_most_orders\": \"data['customer_state'].mode()[0]\",\n    \"top_5_cities_by_orders\": \"data['customer_city'].value_counts().nlargest(5)\",\n    \"top_5_states_by_orders\": \"data['customer_state'].value_counts().nlargest(5)\",\n    \"top_3_states_by_sales\": \"data.groupby('customer_state')['price'].sum().nlargest(3)\",\n    \"sales_per_state\": \"data.groupby('customer_state')['price'].sum()\", # New: Total sales per state\n    \"orders_by_state_and_city\": \"data.groupby(['customer_state', 'customer_city'])['order_status'].count().sort_values(ascending=False)\", # New: Orders by state and city\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:31:52.566412Z","iopub.execute_input":"2025-08-16T09:31:52.566699Z","iopub.status.idle":"2025-08-16T09:31:52.572292Z","shell.execute_reply.started":"2025-08-16T09:31:52.566676Z","shell.execute_reply":"2025-08-16T09:31:52.571506Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def run_query_with_llm(query, df):\n    \"\"\"\n    Asks the LLM to identify a keyword, executes the pandas expression,\n    and then asks the LLM to format the result into a readable sentence.\n    \"\"\"\n    # Step 1: Ask the LLM for a keyword.\n    keyword_prompt = f\"\"\"\n    You are an expert data analyst. You are given a pandas DataFrame named 'data'.\n    Your task is to identify which of the following keywords best answers the user's query:\n    \n    Keywords: {list(PANDAS_EXPRESSIONS.keys())}\n    \n    Please provide only the single keyword that is the best match. Do not provide any other text or explanation.\n\n    Query: {query}\n    \n    Response:\n    \"\"\"\n\n    try:\n        keyword = llm.invoke(keyword_prompt).strip()\n        \n        if keyword in PANDAS_EXPRESSIONS:\n            expression_to_run = PANDAS_EXPRESSIONS[keyword]\n            print(f\"Executing this expression: {expression_to_run}\")\n            \n            # Step 2: Execute the code to get the raw result.\n            raw_result = eval(expression_to_run, {'data': df, 'pd': pd})\n            \n            # Step 3: Create a new prompt to format the output.\n            formatting_prompt = f\"\"\"\n            You are an expert data analyst. The user asked a question and you have the result of a data query.\n            Please format the raw result into a clear, professional, and conversational sentence.\n            Do not just print the numbers. Explain what they mean.\n\n            User Query: {query}\n            Raw Result: {raw_result}\n\n            Formatted Answer:\n            \"\"\"\n            \n            # Step 4: Ask the LLM to format the result.\n            formatted_answer = llm.invoke(formatting_prompt).strip()\n            \n            return formatted_answer\n            \n        else:\n            return f\"The LLM returned an invalid keyword: {keyword}\"\n\n    except Exception as e:\n        return f\"An error occurred while executing the code: {e}\"\n\nprint(\"Custom query function defined with a new, more robust approach.\")\n\n# Cell 4: Interactive Query with a continuous loop\n# This cell takes user input in a loop and prints the final answer.\nwhile True:\n    user_query = input(\"Give me Your Question About Your Data (type 'exit' to quit): \")\n    if user_query.lower() == 'exit':\n        break\n    response = run_query_with_llm(user_query, data)\n    print(f\"Insight: {response}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:31:55.354645Z","iopub.execute_input":"2025-08-16T09:31:55.355235Z","iopub.status.idle":"2025-08-16T09:33:02.753503Z","shell.execute_reply.started":"2025-08-16T09:31:55.35521Z","shell.execute_reply":"2025-08-16T09:33:02.752914Z"}},"outputs":[{"name":"stdout","text":"Custom query function defined with a new, more robust approach.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Give me Your Question About Your Data (type 'exit' to quit):  What is the average total price of an order?\n"},{"name":"stdout","text":"Executing this expression: data['price'].mean()\nInsight: The average total price of an order is 126.05677244835469.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Give me Your Question About Your Data (type 'exit' to quit):  What is the total value of all payments?\n"},{"name":"stdout","text":"Executing this expression: data['payment_value'].sum()\nInsight: The total value of all payments is 16476435.85513522.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Give me Your Question About Your Data (type 'exit' to quit):  What is the average price for each product category?\n"},{"name":"stdout","text":"Executing this expression: data.groupby('category')['price'].mean()\nInsight: The average price for each product category is 342.189179 air conditioning 184.594382 art 115.404354 arts_and_craftmanship 76.700435 audio 141.548367 ... stationery 94.725596 tablets_printing_image 90.412750 telephony 73.172877 toys 120.044977 watches_gifts 210.386230\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Give me Your Question About Your Data (type 'exit' to quit):  exit\n"}],"execution_count":22},{"cell_type":"markdown","source":"## LLM For Recommenditions","metadata":{}},{"cell_type":"code","source":"def run_query_with_llm(query, df):\n    \"\"\"\n    Asks the LLM to identify a keyword, executes the pandas expression,\n    and then asks the LLM to format the result into a readable sentence.\n    Returns both the formatted answer and the keyword.\n    \"\"\"\n    keyword_prompt = f\"\"\"\n    You are an expert data analyst. You are given a pandas DataFrame named 'data'.\n    Your task is to identify which of the following keywords best answers the user's query:\n    \n    Keywords: {list(PANDAS_EXPRESSIONS.keys())}\n    \n    Please provide only the single keyword that is the best match. Do not provide any other text or explanation.\n\n    Query: {query}\n    \n    Response:\n    \"\"\"\n    try:\n        keyword = llm.invoke(keyword_prompt).strip()\n        if keyword in PANDAS_EXPRESSIONS:\n            expression_to_run = PANDAS_EXPRESSIONS[keyword]\n            print(f\"Executing this expression: {expression_to_run}\")\n            raw_result = eval(expression_to_run, {'data': df, 'pd': pd})\n            formatting_prompt = f\"\"\"\n            You are an expert data analyst. The user asked a question and you have the result of a data query.\n            Please format the raw result into a clear, professional, and conversational sentence.\n            Do not just print the numbers. Explain what they mean.\n            User Query: {query}\n            Raw Result: {raw_result}\n            Formatted Answer:\n            \"\"\"\n            formatted_answer = llm.invoke(formatting_prompt).strip()\n            return formatted_answer, keyword\n        else:\n            return f\"The LLM returned an invalid keyword: {keyword}\", None\n    except Exception as e:\n        # Fixed: This line now returns two values to prevent the ValueError\n        return f\"An error occurred while executing the code: {e}\", None\n\nprint(\"Custom query function defined with a new, more robust approach.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:33:10.953082Z","iopub.execute_input":"2025-08-16T09:33:10.953402Z","iopub.status.idle":"2025-08-16T09:33:10.959841Z","shell.execute_reply.started":"2025-08-16T09:33:10.95338Z","shell.execute_reply":"2025-08-16T09:33:10.959188Z"}},"outputs":[{"name":"stdout","text":"Custom query function defined with a new, more robust approach.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## We will Test The Model Now By Asking Some Qs About The Data ","metadata":{}},{"cell_type":"markdown","source":"What is the average total price of an order?    \n \nWhat is the total value of all payments?\n\nWhich payment method is the most common?\n\nWhat are the top 5 categories by total sales value?\n\nWhat is the average price for each product category?\n\nHow many unique product categories are there?","metadata":{}},{"cell_type":"code","source":"# Interactive Query with a continuous loop for Insights and Recommendations\n# This cell takes user input, generates an insight, and then generates an e-commerce recommendation.\n\n# Create a second LLM instance, as requested.\nllm2 = llm\n\n# Define the prompt for generating e-commerce recommendations.\nRECOMMENDATION_PROMPT_TEMPLATE = \"\"\"\nYou are an expert e-commerce marketing consultant. Your task is to provide a detailed, actionable, and comprehensive recommendation to a business owner based on a data-driven insight.\n\nPlease use the following format for your response:\n### Key Insight Summary\nBriefly summarize the insight you've been given.\n\n### Importance for the Business\nExplain why this insight is relevant and important for an e-commerce business. What opportunities or challenges does it present?\n\n### Actionable Recommendations\nProvide a list of 2-3 specific and practical steps the business owner can take to leverage this insight. Be creative and think about marketing, inventory, or customer strategy.\n\n### Expected Impact\nConclude with a sentence about the potential positive impact of these actions.\n\nInsight from data analyst: {insight}\n\nDetailed Recommendation:\n\"\"\"\n\nwhile True:\n    user_query = input(\"Give me Your Question About Your Data (type 'exit' to quit): \")\n    if user_query.lower() == 'exit':\n        break\n\n    # Step 1: Get the insightful answer from the data analyst.\n    insightful_answer = run_query_with_llm(user_query, data)\n    print(f\"Insight: {insightful_answer}\")\n\n    # Step 2: Use the second LLM to generate a detailed recommendation.\n    recommendation_prompt = RECOMMENDATION_PROMPT_TEMPLATE.format(insight=insightful_answer)\n    recommendation = llm2.invoke(recommendation_prompt).strip()\n\n    print(f\"Recommendation: {recommendation}\\n\" + \"-\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:33:23.659157Z","iopub.execute_input":"2025-08-16T09:33:23.659472Z","iopub.status.idle":"2025-08-16T09:34:25.780985Z","shell.execute_reply.started":"2025-08-16T09:33:23.659452Z","shell.execute_reply":"2025-08-16T09:34:25.78021Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Give me Your Question About Your Data (type 'exit' to quit):  Which payment method is the most common?\n"},{"name":"stdout","text":"Executing this expression: data['payment_method'].mode()[0]\nInsight: ('The most common payment method is credit card.', 'most_common_payment_type')\nRecommendation: Credit card is the most common payment method.\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Give me Your Question About Your Data (type 'exit' to quit):  How many unique product categories are there?\n"},{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"Executing this expression: data['category'].nunique()\nInsight: ('There are 71 unique product categories.', 'unique_product_categories_count')\nRecommendation: There are 71 unique product categories.\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Give me Your Question About Your Data (type 'exit' to quit):  exit\n"}],"execution_count":24},{"cell_type":"markdown","source":"This is a Good Results\n- The Model Is Already Make Insights and Give critical Recommendations\n- Now We Will Build A localy Strealit App","metadata":{}},{"cell_type":"markdown","source":"## Streamlit App For Analytics ChatBot\nThis section is for the final testing of the chatbot to ensure it functions as expected.","metadata":{}},{"cell_type":"code","source":"# --- 1. Install necessary libraries\n# This includes all the libraries needed for the app to run.\n!pip install streamlit pyngrok transformers accelerate langchain_community --quiet\n!pip install --upgrade \"huggingface_hub[cli]\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T02:17:30.453312Z","iopub.execute_input":"2025-08-14T02:17:30.453816Z","iopub.status.idle":"2025-08-14T02:19:03.073522Z","shell.execute_reply.started":"2025-08-14T02:17:30.45377Z","shell.execute_reply":"2025-08-14T02:19:03.072851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. Write the Streamlit app file ---\n# The app logic is saved to a file named 'app.py'\napp_py_content = '''\nimport streamlit as st\nimport pandas as pd\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\nfrom langchain_community.llms import HuggingFacePipeline\nimport os\nimport torch\n\n# IMPORTANT: The provided API keys are not strictly needed for this\n# application, as we are using a free, local model (flan-t5-xl) and not a reranker.\nHUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\nCOHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n\n# --- LLM and Agent Logic ---\n@st.cache_resource\ndef get_llm_and_agent_components():\n    \"\"\"Loads LLM and defines the agent's expressions and prompts.\"\"\"\n    # Load the specified larger model: flan-t5-xl\n    # Switching from 'google/flan-t5-xl' to 'google/flan-t5-base' to save memory.\n    llm_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n    llm_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-xl\")\n    \n    # Check for GPU and set device accordingly\n    device = 0 if torch.cuda.is_available() else -1\n    llm_pipe = pipeline(\"text2text-generation\", model=llm_model, tokenizer=llm_tokenizer, max_length=512, device=device)\n    llm = HuggingFacePipeline(pipeline=llm_pipe)\n\n    # --- IMPORTANT: These expressions are specific to your dataset columns. ---\n    # The agent's logic relies on these column names. If you upload a different CSV,\n    # you may need to adjust these expressions to match your new column names.\n    PANDAS_EXPRESSIONS = {\n        \"total_orders\": \"len(data)\",\n        \"order_statuses_count\": \"data['order_status'].value_counts()\",\n        \"unique_product_categories_count\": \"data['category'].nunique()\",\n        \"total_sales_value\": \"data['price'].sum()\",\n        \"avg_price_per_product\": \"data['price'].mean()\",\n        \"count_orders_per_category\": \"data.groupby('category')['order_status'].count()\",\n        \"avg_price_per_category\": \"data.groupby('category')['price'].mean()\",\n        \"top_5_categories_by_sales\": \"data.groupby('category')['price'].sum().nlargest(5)\",\n        \"most_common_payment_type\": \"data['payment_method'].mode()[0]\",\n        \"avg_review_score\": \"data['review'].mean()\",\n        \"top_5_states_by_orders\": \"data['customer_state'].value_counts().nlargest(5)\",\n        \"sales_per_state\": \"data.groupby('customer_state')['price'].sum()\",\n    }\n    \n    RECOMMENDATION_PROMPT_TEMPLATE = \"\"\"\n    You are an expert e-commerce marketing consultant. Your task is to provide a detailed, actionable, and comprehensive recommendation to a business owner based on a data-driven insight.\n\n    Insight from data analyst: {insight}\n\n    Detailed Recommendation:\n    \"\"\"\n\n    INSIGHT_FORMATTING_PROMPT = \"\"\"\n    You are an expert data analyst. The user asked a question and you have the result of a data query.\n    Please format the raw result into a clear, professional, and conversational sentence.\n    Do not just print the numbers. Explain what they mean.\n    User Query: {query}\n    Raw Result: {raw_result}\n    Formatted Answer:\n    \"\"\"\n\n    return llm, PANDAS_EXPRESSIONS, RECOMMENDATION_PROMPT_TEMPLATE, INSIGHT_FORMATTING_PROMPT\n\ndef run_query_with_llm(query, df, llm, expressions, insight_prompt, recommendation_prompt_template):\n    \"\"\"\n    Identifies the best pandas expression, executes it, and generates insight and recommendation.\n    \"\"\"\n    keyword_prompt = f\"\"\"\n    You are an expert data analyst. You are given a pandas DataFrame named 'data'.\n    Your task is to identify which of the following keywords best answers the user's query:\n    Keywords: {list(expressions.keys())}\n    Please provide only the single keyword that is the best match. Do not provide any other text or explanation.\n    Query: {query}\n    Response:\n    \"\"\"\n    try:\n        keyword = llm.invoke(keyword_prompt).strip()\n        if keyword in expressions:\n            expression_to_run = expressions[keyword]\n            raw_result = eval(expression_to_run, {'data': df, 'pd': pd})\n            \n            insight_prompt_filled = insight_prompt.format(query=query, raw_result=raw_result)\n            insight = llm.invoke(insight_prompt_filled).strip()\n\n            recommendation_prompt_filled = recommendation_prompt_template.format(insight=insight)\n            recommendation = llm.invoke(recommendation_prompt_filled).strip()\n            \n            return insight, recommendation\n        else:\n            return \"Sorry, I can't find an appropriate analysis for this question.\", \"\"\n    except Exception as e:\n        return f\"An error occurred: {e}\", \"\"\n\n# --- Streamlit App UI ---\nst.set_page_config(page_title=\"E-commerce Analytics Chatbot\", page_icon=\"🛍️\", layout=\"wide\")\nst.title(\"🛍️ E-commerce Analytics Chatbot\")\n\n# --- Initialize Session State ---\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\nif \"data\" not in st.session_state:\n    st.session_state.data = None\n\n# --- File Upload Section ---\nst.header(\"Upload Your CSV File\")\nuploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n\nif uploaded_file is not None:\n    # Read the uploaded file into a DataFrame\n    try:\n        st.session_state.data = pd.read_csv(uploaded_file)\n        st.success(\"File uploaded successfully! You can now start the chat below.\")\n        st.dataframe(st.session_state.data.head())\n    except Exception as e:\n        st.error(f\"Error reading file: {e}\")\n        st.session_state.data = None\n\n# --- Chat Interface ---\nif st.session_state.data is not None:\n    st.markdown(\"---\")\n    st.header(\"Start Chatting\")\n\n    for message in st.session_state.messages:\n        with st.chat_message(message[\"role\"]):\n            st.markdown(message[\"content\"])\n\n    if prompt := st.chat_input(\"What would you like to know about your data?\"):\n        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n        \n        with st.chat_message(\"assistant\"):\n            with st.spinner(\"Analyzing data...\"):\n                llm, PANDAS_EXPRESSIONS, RECOMMENDATION_PROMPT_TEMPLATE, INSIGHT_FORMATTING_PROMPT = get_llm_and_agent_components()\n                insight, recommendation = run_query_with_llm(\n                    prompt, \n                    st.session_state.data, \n                    llm, \n                    PANDAS_EXPRESSIONS, \n                    INSIGHT_FORMATTING_PROMPT, \n                    RECOMMENDATION_PROMPT_TEMPLATE\n                )\n                \n                # --- This multi-line f-string is now correctly formatted ---\n                full_response = f\"\"\"**Insight:**\n{insight}\n\n**Recommendation:**\n{recommendation}\"\"\"\n                st.markdown(full_response)\n        \n        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\nelse:\n    st.info(\"Please upload a CSV file to begin.\")\n'''\nwith open(\"app.py\", \"w\") as f:\n    f.write(app_py_content)\n\n# --- 3. Run the Streamlit app with ngrok ---\n# This part runs the Streamlit app and opens a public URL for it using ngrok\nimport subprocess\nimport time\nimport requests\nfrom pyngrok import ngrok, conf\nimport os\n\n# Set your ngrok auth token.\nNGROK_AUTH_TOKEN = \"31CpEH0DnLmMSw7dD2KeI7wYvq4_3bf1GVWy4pAPVTqRvGoB9\"\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\ndef run_streamlit_app():\n    # Start streamlit app in background\n    # Note: Streamlit may take a bit longer to start with a larger model (flan-t5-xl)\n    proc = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n\n    # Wait for the Streamlit app to start\n    print(\"Waiting for Streamlit app to start...\")\n    # Add a counter for timeout\n    timeout = 180 # Increased timeout to 3 minutes for a very large model\n    start_time = time.time()\n    \n    # Check if the server is up and running before connecting ngrok\n    while time.time() - start_time < timeout:\n        try:\n            # Try to connect to the Streamlit port\n            response = requests.get(\"http://localhost:8501\")\n            if response.status_code == 200:\n                print(\"Streamlit app is running!\")\n                break\n        except requests.exceptions.ConnectionError:\n            print(\"Streamlit not ready yet. Retrying in 5 seconds...\")\n            time.sleep(5)\n    else:\n        # If the loop completes without breaking, the app failed to start\n        print(\"Error: Streamlit app failed to start within the timeout period.\")\n        proc.kill()\n        return\n\n    # Open ngrok tunnel\n    try:\n        # Kill all existing ngrok tunnels before creating a new one\n        ngrok.kill()\n        public_url = ngrok.connect(8501).public_url\n        print(f\"Your Streamlit app is running at: {public_url}\")\n    except Exception as e:\n        print(f\"Failed to start ngrok tunnel: {e}\")\n        ngrok.kill()\n        proc.kill()\n        raise\n\n# Call the function to run the app\nrun_streamlit_app()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T02:19:06.475561Z","iopub.execute_input":"2025-08-14T02:19:06.475856Z","iopub.status.idle":"2025-08-14T02:19:13.649494Z","shell.execute_reply.started":"2025-08-14T02:19:06.475831Z","shell.execute_reply":"2025-08-14T02:19:13.648939Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"-----------------------------------------------------------------\n-----------------------------------------------------------------\n-----------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Ecommerce Assistant\nThis is our Second Feature in The system\n## Environment Setup & Model Loading\n- We will use the **Mistral-7B-Instruct-v0.2** model\n- Here we'll prepare all the necessary tools and libraries to build our application.","metadata":{}},{"cell_type":"code","source":"# Install necessary libraries for RAG\n!pip install -qU transformers accelerate bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:43:42.956859Z","iopub.execute_input":"2025-08-16T09:43:42.957206Z","iopub.status.idle":"2025-08-16T09:43:46.545674Z","shell.execute_reply.started":"2025-08-16T09:43:42.957173Z","shell.execute_reply":"2025-08-16T09:43:46.544696Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Import required modules\nimport os\nimport torch\nfrom transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:45:04.529297Z","iopub.execute_input":"2025-08-16T09:45:04.530065Z","iopub.status.idle":"2025-08-16T09:45:04.53351Z","shell.execute_reply.started":"2025-08-16T09:45:04.530036Z","shell.execute_reply":"2025-08-16T09:45:04.532782Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define the Hugging Face token directly. This is NOT recommended for production.\nuser_secrets = UserSecretsClient()\nHUGGINGFACE_TOKEN = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n\n# Define a function to load the model and tokenizer\ndef load_llm_model(model_name=\"mistralai/Mistral-7B-Instruct-v0.2\", hf_token=HUGGINGFACE_TOKEN):\n    \"\"\"\n    Loads a Hugging Face LLM model and tokenizer using 4-bit quantization.\n    \n    Parameters:\n    - model_name (str): The name of the model to load from Hugging Face.\n    - hf_token (str, optional): The Hugging Face Access Token.\n    \n    Returns:\n    - tuple: A tuple containing the loaded tokenizer and model.\n    \"\"\"\n    print(f\"Loading model: {model_name}...\")\n    \n    # Configure 4-bit quantization for efficient memory usage\n    quantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quant=False\n    )\n    \n    # Load the tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n    \n    # Load the model with quantization and move it to the GPU\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        quantization_config=quantization_config,\n        token=hf_token\n    )\n    \n    print(f\"Model {model_name} loaded successfully!\")\n    return tokenizer, model\n\n# Execute the function to load the model using the hardcoded token\nif HUGGINGFACE_TOKEN:\n    llm_tokenizer, llm_model = load_llm_model(hf_token=HUGGINGFACE_TOKEN)\nelse:\n    print(\"Hugging Face token not found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:47:39.590987Z","iopub.execute_input":"2025-08-16T09:47:39.591295Z","iopub.status.idle":"2025-08-16T09:50:26.721098Z","shell.execute_reply.started":"2025-08-16T09:47:39.591273Z","shell.execute_reply":"2025-08-16T09:50:26.720485Z"}},"outputs":[{"name":"stdout","text":"Loading model: mistralai/Mistral-7B-Instruct-v0.2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08aabcdee6d74315b2112ef85eb18906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d27f89eaa564c4abc97582ae2418d38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c1b06683bf452489c2f70fdd45956d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b22a3cfa2243228cbf0a022f12fc68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c426d944f514054bf8239cc9c922c50"}},"metadata":{}},{"name":"stderr","text":"2025-08-16 09:47:42.997730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755337663.147561      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755337663.191978      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3b3c13a08941329422c0c5c47b4e35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51129671c9424d6589b83d15f787e87f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"758d74553a914a63bb313e888367010e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df9326ceaef4c478ddb7495c800ba47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3b7d509ff4f4c4fa44537d9d113ee8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"465c8d4d37574ec29e27ff2494b1d9ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112d12252da643ca8ffb2d252797bb9d"}},"metadata":{}},{"name":"stdout","text":"Model mistralai/Mistral-7B-Instruct-v0.2 loaded successfully!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Books Uploading & Embedding \nHere, we'll focus on uploading documents and creating embeddings to build our knowledge base.","metadata":{}},{"cell_type":"code","source":"!pip install pypdf faiss-cpu sentence-transformers cohere langchain-cohere langchain-core -q\n!pip install -U langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:12.589482Z","iopub.execute_input":"2025-08-16T09:51:12.589866Z","iopub.status.idle":"2025-08-16T09:51:19.575711Z","shell.execute_reply.started":"2025-08-16T09:51:12.589836Z","shell.execute_reply":"2025-08-16T09:51:19.574751Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.66)\nRequirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\nRequirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Import necessary modules\nimport os\nfrom typing import List\nfrom langchain_core.documents import Document\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:22.269445Z","iopub.execute_input":"2025-08-16T09:51:22.27022Z","iopub.status.idle":"2025-08-16T09:51:23.343512Z","shell.execute_reply.started":"2025-08-16T09:51:22.270177Z","shell.execute_reply":"2025-08-16T09:51:23.342924Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Function to load documents from a specified directory\ndef load_documents(directory):\n    \"\"\"\n    Loads all PDF documents from a given directory.\n    \"\"\"\n    documents = []\n    for file_name in os.listdir(directory):\n        if file_name.endswith('.pdf'):\n            file_path = os.path.join(directory, file_name)\n            loader = PyPDFLoader(file_path)\n            documents.extend(loader.load())\n            print(f\"Loaded {file_name}\")\n    return documents\n\n\ndef split_documents(documents: List[Document]) -> List[Document]:\n    \"\"\"\n    Splits a list of documents into smaller, more manageable chunks.\n    \"\"\"\n    # We will use RecursiveCharacterTextSplitter for more effective chunking\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200,\n        length_function=len\n    )\n    \n    text_chunks = text_splitter.split_documents(documents)\n    return text_chunks\n\n\n# Function to create and save the vector store\ndef create_vector_store(chunks, save_path=\"faiss_index\"):\n    \"\"\"\n    Creates and saves a FAISS vector store from text chunks.\n    \"\"\"\n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    vector_store = FAISS.from_documents(chunks, embeddings)\n    vector_store.save_local(save_path)\n    print(f\"Vector store saved to {save_path}\")\n    return vector_store","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:24.606108Z","iopub.execute_input":"2025-08-16T09:51:24.606387Z","iopub.status.idle":"2025-08-16T09:51:24.612363Z","shell.execute_reply.started":"2025-08-16T09:51:24.606367Z","shell.execute_reply":"2025-08-16T09:51:24.611609Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Execute the functions to create and save the vector store\n\nif __name__ == \"__main__\":\n    # Define the directory where your dataset is located\n    data_directory = \"/kaggle/input/e-commercee-books\"\n    \n    # 1. Load documents\n    loaded_documents = load_documents(data_directory)\n    \n    if loaded_documents:\n        # 2. Split documents into chunks\n        text_chunks = split_documents(loaded_documents)\n        print(f\"Total chunks created: {len(text_chunks)}\")\n        \n        # 3. Create and save the vector store\n        vector_store = create_vector_store(text_chunks)\n    else:\n        print(\"No PDF documents found. Please ensure your files are in the specified dataset.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:25.36419Z","iopub.execute_input":"2025-08-16T09:51:25.36489Z","iopub.status.idle":"2025-08-16T09:51:43.045551Z","shell.execute_reply.started":"2025-08-16T09:51:25.364868Z","shell.execute_reply":"2025-08-16T09:51:43.044826Z"}},"outputs":[{"name":"stdout","text":"Loaded E-Commerce  (1).pdf\nLoaded E- Commerce (2).pdf\nLoaded E- Commerce.pdf\nTotal chunks created: 1246\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/850394537.py:36: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab78a08f28d541b89809b6b127a60e67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a480c9dfc54b45b6301174e2438d92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5044f9106d5e4c58b342ca6b63daccbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd3c6061abd47bb9fd4ad4be8807e49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f4849dd358f4b0da28142a44c30acb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb39db305304b32b0a88364250ce136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e0cc6edc3e349118a8665bfc7765234"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22fc3ebea6394a4b9370b02697cbb5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea197c4759f04553b2dd425a4c2dab09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"915ebb44d388455098e75652838c893e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d51d068e3a9048308fe28d54769e2c6b"}},"metadata":{}},{"name":"stdout","text":"Vector store saved to faiss_index\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## History-Aware & Re-Ranking RAG\nWe'll enhance the RAG system to be aware of conversation history and re-rank search results for more accurate, contextual answers.","metadata":{}},{"cell_type":"markdown","source":"### Full Pipline","metadata":{}},{"cell_type":"code","source":"# Import necessary modules\nimport os\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport torch\nimport warnings\nimport transformers\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_cohere import CohereRerank\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom collections import deque\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:43.046898Z","iopub.execute_input":"2025-08-16T09:51:43.047504Z","iopub.status.idle":"2025-08-16T09:51:44.86569Z","shell.execute_reply.started":"2025-08-16T09:51:43.047483Z","shell.execute_reply":"2025-08-16T09:51:44.864889Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# --- 1. Load FAISS Index ---\ndef load_faiss_index(index_path=\"faiss_index\"):\n    \"\"\"Loads a previously saved FAISS vector store.\"\"\"\n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    faiss_index = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n    return faiss_index\n\n# --- 2. Create Re-ranker ---\ndef create_reranker(cohere_api_key):\n    \"\"\"Initializes a Cohere Re-ranker.\"\"\"\n    return CohereRerank(cohere_api_key=cohere_api_key, model=\"rerank-english-v3.0\", top_n=3)\n\n# Load the FAISS index\nfaiss_index = load_faiss_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:44.866537Z","iopub.execute_input":"2025-08-16T09:51:44.867158Z","iopub.status.idle":"2025-08-16T09:51:45.613387Z","shell.execute_reply.started":"2025-08-16T09:51:44.867138Z","shell.execute_reply":"2025-08-16T09:51:45.612823Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\n# --- Load Cohere API Key from Kaggle Secrets ---\ntry:\n    user_secrets = UserSecretsClient()\n    cohere_api_key = user_secrets.get_secret(\"COHERE_API_KEY\")\nexcept Exception as e:\n    raise ValueError(f\"Error loading Cohere API key from Kaggle secrets: {e}\")\n\n# Create the reranker instance\nreranker = create_reranker(cohere_api_key)\n\n# --- 2. Create the LLM Pipeline ---\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=llm_model,\n    tokenizer=llm_tokenizer,\n    max_new_tokens=512,\n    do_sample=True,\n    temperature=0.7\n)\n\n# --- 3. Initialize chat loop variables ---\nprint(\"Chatbot is ready. You can start asking questions. Type 'exit' to end the chat.\")\n\nchat_history = \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:45.614677Z","iopub.execute_input":"2025-08-16T09:51:45.614938Z","iopub.status.idle":"2025-08-16T09:51:46.082877Z","shell.execute_reply.started":"2025-08-16T09:51:45.614916Z","shell.execute_reply":"2025-08-16T09:51:46.082319Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Chatbot is ready. You can start asking questions. Type 'exit' to end the chat.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Final ChatBot Test\nThis section is for the final testing of the chatbot to ensure it functions as expected.","metadata":{}},{"cell_type":"markdown","source":"- What are the benefits of E-Marketing?\n- Can you elaborate on 'E-Marketing' as a concept?","metadata":{}},{"cell_type":"code","source":"# A double-ended queue to store the history.\nchat_history_list = deque(maxlen=5)\n\nwhile True:\n    user_query = input(\"You: \")\n    if user_query.lower() == 'exit':\n        print(\"Chatbot: Goodbye!\")\n        break\n    \n    try:\n        # Step A: Retrieve and re-rank relevant documents\n        # The base retriever will fetch the top 10 documents based on similarity.\n        base_retriever = faiss_index.as_retriever(search_kwargs={\"k\": 10})\n        \n        # The ContextualCompressionRetriever uses the reranker to select the best 3 documents from the initial 10.\n        compressed_retriever = ContextualCompressionRetriever(\n            base_compressor=reranker,\n            base_retriever=base_retriever\n        )\n        \n        # Get the final re-ranked documents\n        docs = compressed_retriever.get_relevant_documents(user_query)\n        context = \"\\n\".join([doc.page_content for doc in docs])\n        \n        # Format the chat history list into a string for the prompt\n        chat_history = \"\"\n        for human_message, assistant_message in chat_history_list:\n            chat_history += f\"Human: {human_message}\\nAssistant: {assistant_message}\\n\"\n        \n        # Step B: Build the improved prompt\n        prompt_template = f\"\"\"\n        You are an e-commerce assistant. Your goal is to provide concise and helpful answers based only on the provided context and chat history.\n        Do not make up information. If the answer is not in the provided documents, say \"I don't know the answer based on the provided context.\"\n\n        Chat History:\n        {chat_history}\n\n        Context:\n        {context}\n\n        Question:\n        {user_query}\n\n        Answer:\n        \"\"\"\n\n        # Step C: Generate the response from the LLM pipeline\n        response = pipeline(prompt_template)[0]['generated_text']\n\n        # Step D: Post-process the response to get only the answer\n        if \"Answer:\" in response:\n            answer_text = response.split(\"Answer:\", 1)[1].strip()\n        else:\n            answer_text = response.strip()\n            \n        print(f\"Chatbot: {answer_text}\")\n\n        # Step E: Update the history list for the next turn\n        chat_history_list.append((user_query, answer_text))\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T09:51:55.5673Z","iopub.execute_input":"2025-08-16T09:51:55.568013Z","iopub.status.idle":"2025-08-16T09:52:28.319916Z","shell.execute_reply.started":"2025-08-16T09:51:55.567991Z","shell.execute_reply":"2025-08-16T09:52:28.319263Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"You:  What are the benefits of E-Marketing?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Chatbot: Based on the provided context, the benefits of E-Marketing include global reach, lower cost, measurable results, round-the-clock availability, one-to-one marketing, better conversion rate, and instant information. E-Marketing involves the use of online networks, computer communication, and digital interactive media to help sell goods or services. It adds a new element to the marketing mix and is flexible and cost-effective.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  Can you elaborate on 'E-Marketing' as a concept?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Chatbot: Based on the provided context, E-Marketing is the process of conducting marketing activities through electronic medium. It includes the use of computer, internet and other digital systems to exchange goods or services and determine their value. E-Marketing involves the use of online networks, computer communication, and digital interactive media to attract, win, and retain customers. It adds a new element to the marketing mix and is flexible, cost-effective, and can help develop intimate customer relationships. It saves time and money, attracts analytical buyers, removes distance barriers, provides choice, and enables data collection. E-Marketing is growing due to advancements in science and technology, creative ideas, and the emergence of e-consultants. Examples of E-Marketing tactics include e-mail, banner ads, referrals, and video ads. Businesses like Sify.com and naukri.com use E-Marketing to provide services and help customers.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"},{"name":"stdout","text":"Chatbot: Goodbye!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Streamlit App For ChatBot\nWe will use Streamlit to create a dedicated app for the chatbot, providing a user-friendly interface.","metadata":{}},{"cell_type":"code","source":"# Install necessary libraries for the Streamlit app and ngrok\n# Run this code in a single cell inside a Kaggle Notebook\n!pip install streamlit\n!pip install pyngrok\n# Install libraries for the RAG app\n!pip install -q -U \"langchain[full]\" cohere huggingface_hub transformers bitsandbytes accelerate sentence-transformers faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T10:07:23.329207Z","iopub.status.idle":"2025-08-14T10:07:23.32948Z","shell.execute_reply.started":"2025-08-14T10:07:23.329341Z","shell.execute_reply":"2025-08-14T10:07:23.329351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport streamlit as st\nimport subprocess\nfrom threading import Thread\nimport time\nimport torch\nfrom transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\nfrom langchain_community.llms import HuggingFacePipeline\nfrom langchain.memory import ConversationBufferWindowMemory\nfrom langchain.prompts import PromptTemplate\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.docstore.document import Document\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain_cohere import CohereRerank\nfrom pyngrok import ngrok, conf\nfrom kaggle_secrets import UserSecretsClient\n\n# --- 1. API Keys (Must be replaced) ---\n# WARNING: In a production environment, it is recommended to use Kaggle Secrets.\nHUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\nCOHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n\n# --- 2. ngrok Setup ---\n# The ngrok auth token is hardcoded here as requested.\n# Please remember that for security best practices, it is recommended to use\n# Kaggle Secrets.\nNGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\n# --- 3. Write the Streamlit app file ---\n# This part of the code creates an app.py file containing the complete RAG application code.\napp_py_content = \"\"\"\nimport streamlit as st\nimport os\nimport torch\nimport transformers\nfrom transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\nfrom langchain_community.llms import HuggingFacePipeline\nfrom langchain.memory import ConversationBufferWindowMemory\nfrom langchain.prompts import PromptTemplate\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_cohere import CohereRerank\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.retrievers import ContextualCompressionRetriever\n\n# IMPORTANT: Replace these values with your actual API keys.\nHUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\nCOHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n\n@st.cache_resource\ndef get_rag_chain():\n    \\\"\\\"\\\"\n    Loads all components and assembles the RAG chain.\n    This function runs only once due to @st.cache_resource.\n    \\\"\\\"\\\"\n    # Configure 4-bit quantization for efficient memory usage\n    if torch.cuda.is_available():\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_use_double_quant=False\n        )\n        device_map = \"auto\"\n    else:\n        st.warning(\"CUDA is not available. Running the model on CPU may be very slow.\")\n        quantization_config = None\n        device_map = None\n\n    # Load the LLM Model and tokenizer\n    model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n    llm_tokenizer = AutoTokenizer.from_pretrained(model_name, token=HUGGINGFACE_TOKEN)\n    llm_model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        device_map=device_map,\n        trust_remote_code=True,\n        quantization_config=quantization_config,\n        token=HUGGINGFACE_TOKEN\n    )\n    llm_tokenizer.pad_token_id = llm_tokenizer.eos_token_id\n    \n    # Create the LLM pipeline\n    pipeline = HuggingFacePipeline(\n        pipeline=transformers.pipeline(\n            \"text-generation\",\n            model=llm_model,\n            tokenizer=llm_tokenizer,\n            max_new_tokens=512,\n            do_sample=True,\n            temperature=0.7\n        )\n    )\n\n    # Load the FAISS Index\n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    faiss_index_path = \"faiss_index\"\n    \n    try:\n        faiss_index = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n    except Exception as e:\n        st.error(f\"Error loading FAISS index. Please ensure the 'faiss_index' directory exists and is correctly populated: {e}\")\n        st.stop()\n\n    # Create the Reranker\n    reranker = CohereRerank(cohere_api_key=COHERE_API_KEY, model=\"rerank-english-v3.0\", top_n=5)\n    \n    # Create the Retriever with Re-ranking\n    base_retriever = faiss_index.as_retriever(search_kwargs={\"k\": 20})\n    compressed_retriever = ContextualCompressionRetriever(\n        base_compressor=reranker,\n        base_retriever=base_retriever\n    )\n\n    # Create the Memory and Prompt\n    prompt_template = \\\"\\\"\\\"You are an e-commerce assistant. Use the following context and chat history to answer the question.\n    If the answer is not in the provided documents, say \"I don't know the answer based on the provided context.\"\n    Chat History:\n    {chat_history}\n    Context:\n    {context}\n    Question:\n    {question}\n    Answer:\\\"\\\"\\\"\n    \n    memory = ConversationBufferWindowMemory(\n        k=3,\n        memory_key=\"chat_history\",\n        return_messages=True\n    )\n\n    # Assemble the full Conversational RAG Chain\n    qa_chain = ConversationalRetrievalChain.from_llm(\n        llm=pipeline,\n        retriever=compressed_retriever,\n        memory=memory,\n        combine_docs_chain_kwargs={\n            \"prompt\": PromptTemplate(template=prompt_template, input_variables=[\"chat_history\", \"context\", \"question\"])\n        }\n    )\n    \n    return qa_chain\n\n# --- Streamlit App UI ---\nrag_chain = get_rag_chain()\nst.set_page_config(page_title=\"E-Commerce Assistant\", page_icon=\"🛍️\")\nst.title(\"E-Commerce Assistant\")\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n\nif prompt := st.chat_input(\"How can I help you?\"):\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    with st.chat_message(\"user\"):\n        st.markdown(prompt)\n\n    with st.chat_message(\"assistant\"):\n        with st.spinner(\"Thinking...\"):\n            # Invoke the RAG chain\n            response = rag_chain.invoke({\"question\": prompt})\n            answer_text = response.get('answer', '')\n            \n            # --- Robust answer cleaning logic to only return the answer ---\n            # This logic mimics the successful interactive code to ensure only the final answer is shown.\n            cleaned_answer = \"\"\n            # The model's output might contain the whole prompt, we need to extract the part after 'Answer:'\n            if \"Answer:\" in answer_text:\n                # Find the last occurrence of \"Answer:\" to handle cases where it might appear in chat history\n                last_answer_index = answer_text.rfind(\"Answer:\")\n                cleaned_answer = answer_text[last_answer_index + len(\"Answer:\"):].strip()\n            else:\n                # As a fallback, simply take the entire text if the label is missing\n                cleaned_answer = answer_text.strip()\n            \n            st.markdown(cleaned_answer)\n    \n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": cleaned_answer})\n\"\"\"\nwith open(\"app.py\", \"w\") as f:\n    f.write(app_py_content)\n\n# --- 4. Run the Streamlit app with ngrok ---\n# This part runs the Streamlit app and opens a public URL for it using ngrok\ndef run_streamlit_app():\n    # Install pyngrok\n    os.system(\"pip install pyngrok --quiet\")\n\n    # Start streamlit app in background\n    proc = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n\n    # Wait for the Streamlit app to start on port 8501\n    time.sleep(10)\n    \n    # Open ngrok tunnel to the Streamlit app\n    try:\n        public_url = ngrok.connect(8501).public_url\n        print(f\"Your Streamlit app is running at: {public_url}\")\n    except Exception as e:\n        print(f\"Failed to start ngrok tunnel: {e}\")\n        ngrok.kill()\n        proc.kill()\n        raise\n\nrun_streamlit_app()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T09:16:05.499045Z","iopub.execute_input":"2025-08-14T09:16:05.499854Z","iopub.status.idle":"2025-08-14T09:16:27.968855Z","shell.execute_reply.started":"2025-08-14T09:16:05.499822Z","shell.execute_reply":"2025-08-14T09:16:27.968242Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Thanks\n* LinkedIn :[Hossam Taha](https://www.linkedin.com/in/hossam-taha-41b724288)","metadata":{}}]}